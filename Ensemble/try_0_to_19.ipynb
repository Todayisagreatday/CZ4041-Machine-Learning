{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do average voting using multiple Light Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import multiprocessing\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_path = 'models/lgbm/'\n",
    "output_dir_path = 'output/lgbm/'\n",
    "\n",
    "os.makedirs(model_dir_path, exist_ok=True)\n",
    "os.makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "train_transaction_data_path = 'data/train_transaction.csv'\n",
    "train_identity_data_path = 'data/train_identity.csv'\n",
    "test_transaction_data_path = 'data/test_transaction.csv'\n",
    "test_identity_data_path = 'data/test_identity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define utility function to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Reduce dataframe size\n",
    "\n",
    "    params:\n",
    "    - df: dataframe to reduce the size of\n",
    "\n",
    "    return:\n",
    "    - dataframe of reduced size\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'float128']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                elif c_min > np.finfo(np.float128).min and c_max < np.finfo(np.float128).max:\n",
    "                    df[col] = df[col].astype(np.float128)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose: \n",
    "        print(\n",
    "            'Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "        ))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list down useless features (known from feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_features = [\n",
    "    'TransactionID',  # not really a feature\n",
    "    'dist2',  # transaction features\n",
    "    'C3',  # C features\n",
    "    'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14',  # D features\n",
    "    'M1',  # M features\n",
    "    'id_07', 'id_08', 'id_18', 'id_21', 'id_22', 'id_23',  # id features\n",
    "    'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_35',  # id features\n",
    "    'V6', 'V8', 'V9', 'V10', 'V11', 'V14', 'V15', 'V16',  # V features\n",
    "    'V18', 'V21', 'V22', 'V27', 'V28', 'V31', 'V32',  # V features\n",
    "    'V41', 'V42', 'V46', 'V50', 'V51', 'V59', 'V65',  # V features\n",
    "    'V68', 'V71', 'V72', 'V79', 'V80', 'V84', 'V85',  # V features\n",
    "    'V88', 'V89', 'V92', 'V93', 'V95', 'V98', 'V101',  # V features\n",
    "    'V104', 'V106', 'V107', 'V108', 'V109', 'V110',  # V features\n",
    "    'V111', 'V112', 'V113', 'V114', 'V116', 'V117',  # V features\n",
    "    'V118', 'V119', 'V120', 'V121', 'V122', 'V123',  # V features \n",
    "    'V125', 'V138', 'V141', 'V142', 'V144', 'V146',  # V features \n",
    "    'V147', 'V148', 'V151', 'V153', 'V154', 'V155',  # V features \n",
    "    'V157', 'V158', 'V159', 'V161', 'V163', 'V164',  # V features \n",
    "    'V166', 'V172', 'V173', 'V174', 'V175', 'V176',  # V features \n",
    "    'V177', 'V178', 'V179', 'V180', 'V181', 'V182',  # V features  \n",
    "    'V183', 'V184', 'V185', 'V186', 'V190', 'V191',  # V features  \n",
    "    'V192', 'V193', 'V194', 'V195', 'V196', 'V197',  # V features  \n",
    "    'V198', 'V199', 'V214', 'V216', 'V220', 'V225',  # V features \n",
    "    'V226', 'V227', 'V230', 'V233', 'V235', 'V236',  # V features  \n",
    "    'V237', 'V238', 'V239', 'V240', 'V241', 'V242',  # V features \n",
    "    'V244', 'V246', 'V247', 'V248', 'V249', 'V250',  # V features \n",
    "    'V252', 'V254', 'V255', 'V269', 'V276', 'V297',  # V features \n",
    "    'V300', 'V302', 'V304', 'V305', 'V325', 'V327',  # V features  \n",
    "    'V328', 'V329', 'V330', 'V334', 'V335', 'V336',  # V features \n",
    "    'V337', 'V338', 'V339',  # V features \n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard OS versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_os_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_30 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after os versions have been ignored\n",
    "    \"\"\"\n",
    "    os_list = [\n",
    "        'Android',\n",
    "        'iOS',\n",
    "        'Mac OS X',\n",
    "        'Windows',\n",
    "    ]\n",
    "\n",
    "    for index, operating_system in df.id_30.iteritems():\n",
    "        new_os = 'other'\n",
    "\n",
    "        if isinstance(operating_system, str):\n",
    "            for known_os in os_list:\n",
    "                if known_os in operating_system:\n",
    "                    new_os = known_os\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_30'] = new_os\n",
    "\n",
    "    if verbose:\n",
    "        print('operating systems:', df.id_30.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard browser versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_browser_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_31 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after browser versions have been ignored\n",
    "    \"\"\"\n",
    "    browser_list = [\n",
    "        'aol',\n",
    "        'chrome',\n",
    "        'chromium',\n",
    "        'comodo',\n",
    "        'cyberfox',\n",
    "        'edge',\n",
    "        'firefox',\n",
    "        'icedragon',\n",
    "        'ie',\n",
    "        'iron',\n",
    "        'maxthon',\n",
    "        'opera',\n",
    "        'palemoon',\n",
    "        'puffin',\n",
    "        'safari',\n",
    "        'samsung',\n",
    "        'seamonkey',\n",
    "        'silk',\n",
    "        'waterfox',\n",
    "    ]\n",
    "\n",
    "    for index, browser in df.id_31.iteritems():\n",
    "        new_browser = 'other'\n",
    "\n",
    "        if isinstance(browser, str):\n",
    "            for known_browser in browser_list:\n",
    "                if known_browser in browser:\n",
    "                    new_browser = known_browser\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_31'] = new_browser\n",
    "\n",
    "    if verbose:\n",
    "        print('browsers:', df.id_31.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    Does the following preprocessing steps:\n",
    "    - disregard os versions\n",
    "    - disregard browser versions\n",
    "    - drop useless features\n",
    "    - convert object columns to string columns\n",
    "    - imputation (for numbers, fill with interquartile mean)\n",
    "    - do label encoding for non-numeric values\n",
    "    - reduce memory usage again\n",
    "\n",
    "    params:   \n",
    "    - df (DataFrame): dataframe to preprocess (has columns id_30 and id_31)\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, preprocessing is complete\n",
    "    \"\"\"\n",
    "    df = df.drop(useless_features, axis=1)\n",
    "    df = ignore_os_version(df, verbose)\n",
    "    df = ignore_browser_version(df, verbose)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column]= df[column].astype(str)\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].quantile().mean())\n",
    "\n",
    "    df = reduce_mem_usage(df, verbose)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 472.59 Mb (68.9% reduction)\nMem. usage decreased to 25.44 Mb (42.7% reduction)\nnumber of rows in test data: 506691\noperating systems: ['other' 'Android' 'iOS' 'Windows' 'Mac OS X']\nbrowsers: ['other' 'chrome' 'ie' 'safari' 'edge' 'firefox' 'samsung' 'opera'\n 'palemoon']\nMem. usage decreased to 315.73 Mb (21.6% reduction)\nCPU times: user 1min 3s, sys: 31 s, total: 1min 34s\nWall time: 1min 34s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  card4  \\\n0       18403224       31.953125          4  10409  111.0  150.0      4   \n1       18403263       49.000000          4   4272  111.0  150.0      4   \n2       18403310      171.000000          4   4476  574.0  150.0      4   \n3       18403310      285.000000          4  10989  360.0  150.0      4   \n4       18403317       67.937500          4  18018  452.0  150.0      2   \n\n   card5  card6  addr1  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0  226.0      2  170.0  ...      4      5   24.0    390      2      2      2   \n1  226.0      2  299.0  ...      4      5   24.0    390      2      2      2   \n2  226.0      2  472.0  ...      4      5   24.0    390      2      2      2   \n3  166.0      2  205.0  ...      4      5   24.0    390      2      2      2   \n4  117.0      2  264.0  ...      4      5   24.0    390      2      2      2   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        2184  \n1      2           2        2184  \n2      2           2        2184  \n3      2           2        2184  \n4      2           2        2184  \n\n[5 rows x 269 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>addr1</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18403224</td>\n      <td>31.953125</td>\n      <td>4</td>\n      <td>10409</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>170.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18403263</td>\n      <td>49.000000</td>\n      <td>4</td>\n      <td>4272</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>299.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18403310</td>\n      <td>171.000000</td>\n      <td>4</td>\n      <td>4476</td>\n      <td>574.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>472.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18403310</td>\n      <td>285.000000</td>\n      <td>4</td>\n      <td>10989</td>\n      <td>360.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>205.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18403317</td>\n      <td>67.937500</td>\n      <td>4</td>\n      <td>18018</td>\n      <td>452.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>264.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 269 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(test_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(test_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "identity_dataframe = identity_dataframe.rename(\n",
    "    columns={\n",
    "        column: column.replace('-', '_')\n",
    "        for column in identity_dataframe.columns\n",
    "    }\n",
    ")\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "transaction_id_data = dataframe['TransactionID']  # need it for output\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in test data: {len(dataframe)}')\n",
    "dataframe = preprocess(dataframe)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define number of base classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_base_classifiers = 20\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load models, do inference and get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "doing inference using lgbm_0\ndoing inference using lgbm_1\ndoing inference using lgbm_2\ndoing inference using lgbm_3\ndoing inference using lgbm_4\ndoing inference using lgbm_5\ndoing inference using lgbm_6\ndoing inference using lgbm_7\ndoing inference using lgbm_8\ndoing inference using lgbm_9\ndoing inference using lgbm_10\ndoing inference using lgbm_11\ndoing inference using lgbm_12\ndoing inference using lgbm_13\ndoing inference using lgbm_14\ndoing inference using lgbm_15\ndoing inference using lgbm_16\ndoing inference using lgbm_17\ndoing inference using lgbm_18\ndoing inference using lgbm_19\nCPU times: user 5h 55min 7s, sys: 34.6 s, total: 5h 55min 41s\nWall time: 33min 37s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionID   isFraud\n0        3663549  0.006293\n1        3663550  0.006006\n2        3663551  0.008165\n3        3663552  0.006538\n4        3663553  0.006053",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3663549</td>\n      <td>0.006293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3663550</td>\n      <td>0.006006</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3663551</td>\n      <td>0.008165</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3663552</td>\n      <td>0.006538</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3663553</td>\n      <td>0.006053</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('doing inference using lgbm_0')\n",
    "classifier = joblib.load(model_dir_path + 'lgbm_' + str(0 + offset) + '.joblib')\n",
    "prediction = classifier.predict(dataframe)\n",
    "\n",
    "for index in range(1, num_base_classifiers):\n",
    "    classifier_name = 'lgbm_' + str(index + offset)\n",
    "    print(f'doing inference using {classifier_name}')\n",
    "\n",
    "    classifier = joblib.load(model_dir_path + classifier_name + '.joblib')\n",
    "    base_prediction = classifier.predict(dataframe)\n",
    "    prediction += base_prediction\n",
    "\n",
    "prediction /= num_base_classifiers  # equal weightage given to each base classifier\n",
    "\n",
    "del classifier\n",
    "del dataframe\n",
    "\n",
    "output_dataframe = pd.DataFrame({\n",
    "    'TransactionID': transaction_id_data,\n",
    "    'isFraud': pd.Series(prediction),\n",
    "})\n",
    "\n",
    "output_dataframe.to_csv(output_dir_path + 'avg_vote_lgbm_0_to_19.csv', index=False)\n",
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle result\n",
    "\n",
    "- public score: 0.941296\n",
    "- public ranking: 3173 out of 6381 (~49.72%)\n",
    "- private score: 0.916027\n",
    "- private ranking: 2558 out of 6381 (~40.08%)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0656ffb61a14454b8758eedef206058e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}