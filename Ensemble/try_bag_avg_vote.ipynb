{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do average voting using multiple Light Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import multiprocessing\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_path = 'models/lgbm/'\n",
    "output_dir_path = 'output/lgbm/'\n",
    "\n",
    "os.makedirs(model_dir_path, exist_ok=True)\n",
    "os.makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "train_transaction_data_path = 'data/train_transaction.csv'\n",
    "train_identity_data_path = 'data/train_identity.csv'\n",
    "test_transaction_data_path = 'data/test_transaction.csv'\n",
    "test_identity_data_path = 'data/test_identity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define utility function to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Reduce dataframe size\n",
    "\n",
    "    params:\n",
    "    - df: dataframe to reduce the size of\n",
    "\n",
    "    return:\n",
    "    - dataframe of reduced size\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'float128']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                elif c_min > np.finfo(np.float128).min and c_max < np.finfo(np.float128).max:\n",
    "                    df[col] = df[col].astype(np.float128)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose: \n",
    "        print(\n",
    "            'Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "        ))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list down useless features (known from feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_features = [\n",
    "    'TransactionID',  # not really a feature\n",
    "    'dist2',  # transaction features\n",
    "    'C3',  # C features\n",
    "    'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14',  # D features\n",
    "    'M1',  # M features\n",
    "    'id_07', 'id_08', 'id_18', 'id_21', 'id_22', 'id_23',  # id features\n",
    "    'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_35',  # id features\n",
    "    'V6', 'V8', 'V9', 'V10', 'V11', 'V14', 'V15', 'V16',  # V features\n",
    "    'V18', 'V21', 'V22', 'V27', 'V28', 'V31', 'V32',  # V features\n",
    "    'V41', 'V42', 'V46', 'V50', 'V51', 'V59', 'V65',  # V features\n",
    "    'V68', 'V71', 'V72', 'V79', 'V80', 'V84', 'V85',  # V features\n",
    "    'V88', 'V89', 'V92', 'V93', 'V95', 'V98', 'V101',  # V features\n",
    "    'V104', 'V106', 'V107', 'V108', 'V109', 'V110',  # V features\n",
    "    'V111', 'V112', 'V113', 'V114', 'V116', 'V117',  # V features\n",
    "    'V118', 'V119', 'V120', 'V121', 'V122', 'V123',  # V features \n",
    "    'V125', 'V138', 'V141', 'V142', 'V144', 'V146',  # V features \n",
    "    'V147', 'V148', 'V151', 'V153', 'V154', 'V155',  # V features \n",
    "    'V157', 'V158', 'V159', 'V161', 'V163', 'V164',  # V features \n",
    "    'V166', 'V172', 'V173', 'V174', 'V175', 'V176',  # V features \n",
    "    'V177', 'V178', 'V179', 'V180', 'V181', 'V182',  # V features  \n",
    "    'V183', 'V184', 'V185', 'V186', 'V190', 'V191',  # V features  \n",
    "    'V192', 'V193', 'V194', 'V195', 'V196', 'V197',  # V features  \n",
    "    'V198', 'V199', 'V214', 'V216', 'V220', 'V225',  # V features \n",
    "    'V226', 'V227', 'V230', 'V233', 'V235', 'V236',  # V features  \n",
    "    'V237', 'V238', 'V239', 'V240', 'V241', 'V242',  # V features \n",
    "    'V244', 'V246', 'V247', 'V248', 'V249', 'V250',  # V features \n",
    "    'V252', 'V254', 'V255', 'V269', 'V276', 'V297',  # V features \n",
    "    'V300', 'V302', 'V304', 'V305', 'V325', 'V327',  # V features  \n",
    "    'V328', 'V329', 'V330', 'V334', 'V335', 'V336',  # V features \n",
    "    'V337', 'V338', 'V339',  # V features \n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard OS versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_os_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_30 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after os versions have been ignored\n",
    "    \"\"\"\n",
    "    os_list = [\n",
    "        'Android',\n",
    "        'iOS',\n",
    "        'Mac OS X',\n",
    "        'Windows',\n",
    "    ]\n",
    "\n",
    "    for index, operating_system in df.id_30.iteritems():\n",
    "        new_os = 'other'\n",
    "\n",
    "        if isinstance(operating_system, str):\n",
    "            for known_os in os_list:\n",
    "                if known_os in operating_system:\n",
    "                    new_os = known_os\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_30'] = new_os\n",
    "\n",
    "    if verbose:\n",
    "        print('operating systems:', df.id_30.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard browser versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_browser_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_31 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after browser versions have been ignored\n",
    "    \"\"\"\n",
    "    browser_list = [\n",
    "        'aol',\n",
    "        'chrome',\n",
    "        'chromium',\n",
    "        'comodo',\n",
    "        'cyberfox',\n",
    "        'edge',\n",
    "        'firefox',\n",
    "        'icedragon',\n",
    "        'ie',\n",
    "        'iron',\n",
    "        'maxthon',\n",
    "        'opera',\n",
    "        'palemoon',\n",
    "        'puffin',\n",
    "        'safari',\n",
    "        'samsung',\n",
    "        'seamonkey',\n",
    "        'silk',\n",
    "        'waterfox',\n",
    "    ]\n",
    "\n",
    "    for index, browser in df.id_31.iteritems():\n",
    "        new_browser = 'other'\n",
    "\n",
    "        if isinstance(browser, str):\n",
    "            for known_browser in browser_list:\n",
    "                if known_browser in browser:\n",
    "                    new_browser = known_browser\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_31'] = new_browser\n",
    "\n",
    "    if verbose:\n",
    "        print('browsers:', df.id_31.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    Does the following preprocessing steps:\n",
    "    - disregard os versions\n",
    "    - disregard browser versions\n",
    "    - drop useless features\n",
    "    - convert object columns to string columns\n",
    "    - imputation (for numbers, fill with interquartile mean)\n",
    "    - do label encoding for non-numeric values\n",
    "    - reduce memory usage again\n",
    "\n",
    "    params:   \n",
    "    - df (DataFrame): dataframe to preprocess (has columns id_30 and id_31)\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, preprocessing is complete\n",
    "    \"\"\"\n",
    "    df = df.drop(useless_features, axis=1)\n",
    "    df = ignore_os_version(df, verbose)\n",
    "    df = ignore_browser_version(df, verbose)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column]= df[column].astype(str)\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].quantile().mean())\n",
    "\n",
    "    df = reduce_mem_usage(df, verbose)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 542.35 Mb (69.4% reduction)\nMem. usage decreased to 25.86 Mb (42.7% reduction)\nnumber of rows in training data: 590540\noperating systems: ['other' 'Android' 'iOS' 'Mac OS X' 'Windows']\nbrowsers: ['other' 'samsung' 'safari' 'chrome' 'edge' 'firefox' 'ie' 'opera' 'aol'\n 'silk' 'waterfox' 'puffin' 'cyberfox' 'palemoon' 'maxthon' 'iron'\n 'seamonkey' 'comodo' 'chromium' 'icedragon']\nMem. usage decreased to 357.35 Mb (22.1% reduction)\nCPU times: user 1min 16s, sys: 37 s, total: 1min 53s\nWall time: 1min 54s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   isFraud  TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  \\\n0        0          86400            68.5          4  13926  361.0  150.0   \n1        0          86401            29.0          4   2755  404.0  150.0   \n2        0          86469            59.0          4   4663  490.0  150.0   \n3        0          86499            50.0          4  18132  567.0  150.0   \n4        0          86506            50.0          1   4497  514.0  150.0   \n\n   card4  card5  card6  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0      1  142.0      1  ...      4     12   24.0    260      4      2      2   \n1      2  102.0      1  ...      4     12   24.0    260      4      2      2   \n2      4  166.0      2  ...      4     12   24.0    260      4      2      2   \n3      2  117.0      2  ...      4     12   24.0    260      4      2      2   \n4      2  102.0      1  ...      0     16   32.0    164      3      0      1   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        1742  \n1      2           2        1742  \n2      2           2        1742  \n3      2           2        1742  \n4      1           1         954  \n\n[5 rows x 270 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>86400</td>\n      <td>68.5</td>\n      <td>4</td>\n      <td>13926</td>\n      <td>361.0</td>\n      <td>150.0</td>\n      <td>1</td>\n      <td>142.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>86401</td>\n      <td>29.0</td>\n      <td>4</td>\n      <td>2755</td>\n      <td>404.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>86469</td>\n      <td>59.0</td>\n      <td>4</td>\n      <td>4663</td>\n      <td>490.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>86499</td>\n      <td>50.0</td>\n      <td>4</td>\n      <td>18132</td>\n      <td>567.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>86506</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>4497</td>\n      <td>514.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16</td>\n      <td>32.0</td>\n      <td>164</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>954</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 270 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(train_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(train_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in training data: {len(dataframe)}')\n",
    "dataframe = preprocess(dataframe)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate data into features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataframe = dataframe.drop('isFraud', axis=1)\n",
    "is_fraud_data = dataframe['isFraud']\n",
    "\n",
    "del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define number of base classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_base_classifiers = 10\n",
    "offset = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train LightGBM\n",
    "\n",
    "- using [reference notebook parameters](https://www.kaggle.com/nroman/lgb-single-model-lb-0-9419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 491,\n",
    "    'min_child_weight': 0.03454472573214212,\n",
    "    'feature_fraction': 0.3797454081646243,\n",
    "    'bagging_fraction': 0.4181193142567742,\n",
    "    'min_data_in_leaf': 106,\n",
    "    'objective': 'binary',\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.006883242363721497,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'bagging_seed': 11,\n",
    "    'metric': 'auc',\n",
    "    'verbosity': -1,\n",
    "    'reg_alpha': 0.3899927210061127,\n",
    "    'reg_lambda': 0.6485237330340494,\n",
    "    'random_state': 47,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "working on base classifier 10\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.99333\tvalid_1's auc: 0.96606\n[2000]\ttraining's auc: 0.999152\tvalid_1's auc: 0.973492\n[3000]\ttraining's auc: 0.999892\tvalid_1's auc: 0.975388\n[4000]\ttraining's auc: 0.999992\tvalid_1's auc: 0.976055\n[5000]\ttraining's auc: 1\tvalid_1's auc: 0.976313\nEarly stopping, best iteration is:\n[5110]\ttraining's auc: 1\tvalid_1's auc: 0.976346\nbase classifier 10 AUC: 0.9763458399638495\nworking on base classifier 11\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993606\tvalid_1's auc: 0.963698\n[2000]\ttraining's auc: 0.999204\tvalid_1's auc: 0.971077\n[3000]\ttraining's auc: 0.999889\tvalid_1's auc: 0.972926\n[4000]\ttraining's auc: 0.999991\tvalid_1's auc: 0.973595\n[5000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.97369\nEarly stopping, best iteration is:\n[5033]\ttraining's auc: 0.999999\tvalid_1's auc: 0.9737\nbase classifier 11 AUC: 0.9737000511033413\nworking on base classifier 12\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993431\tvalid_1's auc: 0.964795\n[2000]\ttraining's auc: 0.999184\tvalid_1's auc: 0.971296\n[3000]\ttraining's auc: 0.99989\tvalid_1's auc: 0.972787\n[4000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.973231\n[5000]\ttraining's auc: 1\tvalid_1's auc: 0.973359\nEarly stopping, best iteration is:\n[5417]\ttraining's auc: 1\tvalid_1's auc: 0.973408\nbase classifier 12 AUC: 0.9734075650572862\nworking on base classifier 13\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993333\tvalid_1's auc: 0.965854\n[2000]\ttraining's auc: 0.999138\tvalid_1's auc: 0.972553\n[3000]\ttraining's auc: 0.99988\tvalid_1's auc: 0.97396\n[4000]\ttraining's auc: 0.999991\tvalid_1's auc: 0.974432\n[5000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.974598\n[6000]\ttraining's auc: 1\tvalid_1's auc: 0.974614\nEarly stopping, best iteration is:\n[5617]\ttraining's auc: 1\tvalid_1's auc: 0.974681\nbase classifier 13 AUC: 0.9746811926560638\nworking on base classifier 14\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993399\tvalid_1's auc: 0.965089\n[2000]\ttraining's auc: 0.999198\tvalid_1's auc: 0.972188\n[3000]\ttraining's auc: 0.999903\tvalid_1's auc: 0.973866\n[4000]\ttraining's auc: 0.999993\tvalid_1's auc: 0.97419\nEarly stopping, best iteration is:\n[4303]\ttraining's auc: 0.999997\tvalid_1's auc: 0.974243\nbase classifier 14 AUC: 0.9742426018062464\nworking on base classifier 15\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.99362\tvalid_1's auc: 0.964557\n[2000]\ttraining's auc: 0.999198\tvalid_1's auc: 0.971184\n[3000]\ttraining's auc: 0.99989\tvalid_1's auc: 0.972547\n[4000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.972819\n[5000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.97298\nEarly stopping, best iteration is:\n[4883]\ttraining's auc: 0.999999\tvalid_1's auc: 0.972984\nbase classifier 15 AUC: 0.9729844433289231\nworking on base classifier 16\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993129\tvalid_1's auc: 0.965336\n[2000]\ttraining's auc: 0.999164\tvalid_1's auc: 0.972168\n[3000]\ttraining's auc: 0.999875\tvalid_1's auc: 0.973695\n[4000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.974119\n[5000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.974204\nEarly stopping, best iteration is:\n[4609]\ttraining's auc: 0.999997\tvalid_1's auc: 0.974227\nbase classifier 16 AUC: 0.9742265491864115\nworking on base classifier 17\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993643\tvalid_1's auc: 0.965384\n[2000]\ttraining's auc: 0.999232\tvalid_1's auc: 0.972343\n[3000]\ttraining's auc: 0.999914\tvalid_1's auc: 0.973824\n[4000]\ttraining's auc: 0.999994\tvalid_1's auc: 0.974146\nEarly stopping, best iteration is:\n[4014]\ttraining's auc: 0.999994\tvalid_1's auc: 0.974155\nbase classifier 17 AUC: 0.9741547240310732\nworking on base classifier 18\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993709\tvalid_1's auc: 0.963224\n[2000]\ttraining's auc: 0.999237\tvalid_1's auc: 0.969942\n[3000]\ttraining's auc: 0.9999\tvalid_1's auc: 0.971421\n[4000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.971775\nEarly stopping, best iteration is:\n[4213]\ttraining's auc: 0.999994\tvalid_1's auc: 0.971811\nbase classifier 18 AUC: 0.9718113115860119\nworking on base classifier 19\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993265\tvalid_1's auc: 0.962845\n[2000]\ttraining's auc: 0.999229\tvalid_1's auc: 0.971174\n[3000]\ttraining's auc: 0.999907\tvalid_1's auc: 0.973115\n[4000]\ttraining's auc: 0.999991\tvalid_1's auc: 0.973656\n[5000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.973754\nEarly stopping, best iteration is:\n[5477]\ttraining's auc: 1\tvalid_1's auc: 0.973766\nbase classifier 19 AUC: 0.9737661817191391\nCPU times: user 1d 10h 25min 31s, sys: 21min 34s, total: 1d 10h 47min 5s\nWall time: 2h 59min 35s\n"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index in range(num_base_classifiers):\n",
    "    classifier_num = index + offset\n",
    "    print(f'working on base classifier {classifier_num}')\n",
    "\n",
    "    train_features, val_features, train_target, val_target = train_test_split(\n",
    "        features_dataframe, \n",
    "        is_fraud_data, \n",
    "        test_size=0.2,\n",
    "    )\n",
    "\n",
    "    train_data = lgb.Dataset(train_features, train_target)\n",
    "    del train_features\n",
    "    del train_target\n",
    "\n",
    "    val_data = lgb.Dataset(val_features, val_target)\n",
    "\n",
    "    params['random_state'] = classifier_num\n",
    "\n",
    "    classifier = lgb.train(\n",
    "        params, \n",
    "        train_set=train_data, \n",
    "        num_boost_round=10000, \n",
    "        valid_sets=[train_data, val_data],\n",
    "        verbose_eval=1000,\n",
    "        early_stopping_rounds=500,\n",
    "    )\n",
    "\n",
    "    joblib.dump(classifier, model_dir_path + 'lgbm_' + str(classifier_num) + '.joblib')\n",
    "\n",
    "    prediction = classifier.predict(val_features)\n",
    "    auc = roc_auc_score(val_target, prediction)\n",
    "    print(f'base classifier {classifier_num} AUC: {auc}')\n",
    "\n",
    "del features_dataframe\n",
    "del is_fraud_data\n",
    "\n",
    "del params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 472.59 Mb (68.9% reduction)\nMem. usage decreased to 25.44 Mb (42.7% reduction)\nnumber of rows in test data: 506691\noperating systems: ['other' 'Android' 'iOS' 'Windows' 'Mac OS X']\nbrowsers: ['other' 'chrome' 'ie' 'safari' 'edge' 'firefox' 'samsung' 'opera'\n 'palemoon']\nMem. usage decreased to 315.73 Mb (21.6% reduction)\nCPU times: user 1min 1s, sys: 30.8 s, total: 1min 32s\nWall time: 1min 32s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  card4  \\\n0       18403224       31.953125          4  10409  111.0  150.0      4   \n1       18403263       49.000000          4   4272  111.0  150.0      4   \n2       18403310      171.000000          4   4476  574.0  150.0      4   \n3       18403310      285.000000          4  10989  360.0  150.0      4   \n4       18403317       67.937500          4  18018  452.0  150.0      2   \n\n   card5  card6  addr1  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0  226.0      2  170.0  ...      4      5   24.0    390      2      2      2   \n1  226.0      2  299.0  ...      4      5   24.0    390      2      2      2   \n2  226.0      2  472.0  ...      4      5   24.0    390      2      2      2   \n3  166.0      2  205.0  ...      4      5   24.0    390      2      2      2   \n4  117.0      2  264.0  ...      4      5   24.0    390      2      2      2   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        2184  \n1      2           2        2184  \n2      2           2        2184  \n3      2           2        2184  \n4      2           2        2184  \n\n[5 rows x 269 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>addr1</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18403224</td>\n      <td>31.953125</td>\n      <td>4</td>\n      <td>10409</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>170.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18403263</td>\n      <td>49.000000</td>\n      <td>4</td>\n      <td>4272</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>299.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18403310</td>\n      <td>171.000000</td>\n      <td>4</td>\n      <td>4476</td>\n      <td>574.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>472.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18403310</td>\n      <td>285.000000</td>\n      <td>4</td>\n      <td>10989</td>\n      <td>360.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>205.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18403317</td>\n      <td>67.937500</td>\n      <td>4</td>\n      <td>18018</td>\n      <td>452.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>264.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 269 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(test_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(test_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "identity_dataframe = identity_dataframe.rename(\n",
    "    columns={\n",
    "        column: column.replace('-', '_')\n",
    "        for column in identity_dataframe.columns\n",
    "    }\n",
    ")\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "transaction_id_data = dataframe['TransactionID']  # need it for output\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in test data: {len(dataframe)}')\n",
    "dataframe = preprocess(dataframe)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model\n",
    "\n",
    "- if model is no longer in memory (e.g. due to restarting of notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    joblib.load(model_dir_path + 'lgbm_' + str(index + offset) + '.joblib')\n",
    "    for index in range(num_base_classifiers)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do inference and get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 4h 55min 9s, sys: 22.9 s, total: 4h 55min 32s\nWall time: 27min 29s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionID   isFraud\n0        3663549  0.000393\n1        3663550  0.000112\n2        3663551  0.000538\n3        3663552  0.000407\n4        3663553  0.000139",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3663549</td>\n      <td>0.000393</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3663550</td>\n      <td>0.000112</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3663551</td>\n      <td>0.000538</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3663552</td>\n      <td>0.000407</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3663553</td>\n      <td>0.000139</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = [\n",
    "    classifier.predict(dataframe)\n",
    "    for classifier in classifiers\n",
    "]\n",
    "\n",
    "prediction = predictions.pop()\n",
    "for pred in predictions:\n",
    "    prediction += pred\n",
    "\n",
    "prediction /= 10  # equal weightage given to each base classifier - 0.1\n",
    "del predictions\n",
    "\n",
    "del classifiers\n",
    "del dataframe\n",
    "\n",
    "output_dataframe = pd.DataFrame({\n",
    "    'TransactionID': transaction_id_data,\n",
    "    'isFraud': pd.Series(prediction),\n",
    "})\n",
    "\n",
    "output_dataframe.to_csv(output_dir_path + 'avg_vote_lgbm_pred.csv', index=False)\n",
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle result\n",
    "\n",
    "- public score: 0.941287\n",
    "- public ranking: 3174 out of 6381 (~49.74%)\n",
    "- private score: 0.913408\n",
    "- private ranking: 2948 out of 6381 (~46.19%)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0656ffb61a14454b8758eedef206058e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}