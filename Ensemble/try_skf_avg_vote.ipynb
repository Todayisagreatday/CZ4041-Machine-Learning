{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do average voting using multiple Light Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import multiprocessing\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_path = 'models/lgbm/'\n",
    "output_dir_path = 'output/lgbm/'\n",
    "\n",
    "os.makedirs(model_dir_path, exist_ok=True)\n",
    "os.makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "train_transaction_data_path = 'data/train_transaction.csv'\n",
    "train_identity_data_path = 'data/train_identity.csv'\n",
    "test_transaction_data_path = 'data/test_transaction.csv'\n",
    "test_identity_data_path = 'data/test_identity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define utility function to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Reduce dataframe size\n",
    "\n",
    "    params:\n",
    "    - df: dataframe to reduce the size of\n",
    "\n",
    "    return:\n",
    "    - dataframe of reduced size\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'float128']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                elif c_min > np.finfo(np.float128).min and c_max < np.finfo(np.float128).max:\n",
    "                    df[col] = df[col].astype(np.float128)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    if verbose: \n",
    "        print(\n",
    "            'Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "        ))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list down useless features (known from feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_features = [\n",
    "    'TransactionID',  # not really a feature\n",
    "    'dist2',  # transaction features\n",
    "    'C3',  # C features\n",
    "    'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14',  # D features\n",
    "    'M1',  # M features\n",
    "    'id_07', 'id_08', 'id_18', 'id_21', 'id_22', 'id_23',  # id features\n",
    "    'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_35',  # id features\n",
    "    'V6', 'V8', 'V9', 'V10', 'V11', 'V14', 'V15', 'V16',  # V features\n",
    "    'V18', 'V21', 'V22', 'V27', 'V28', 'V31', 'V32',  # V features\n",
    "    'V41', 'V42', 'V46', 'V50', 'V51', 'V59', 'V65',  # V features\n",
    "    'V68', 'V71', 'V72', 'V79', 'V80', 'V84', 'V85',  # V features\n",
    "    'V88', 'V89', 'V92', 'V93', 'V95', 'V98', 'V101',  # V features\n",
    "    'V104', 'V106', 'V107', 'V108', 'V109', 'V110',  # V features\n",
    "    'V111', 'V112', 'V113', 'V114', 'V116', 'V117',  # V features\n",
    "    'V118', 'V119', 'V120', 'V121', 'V122', 'V123',  # V features \n",
    "    'V125', 'V138', 'V141', 'V142', 'V144', 'V146',  # V features \n",
    "    'V147', 'V148', 'V151', 'V153', 'V154', 'V155',  # V features \n",
    "    'V157', 'V158', 'V159', 'V161', 'V163', 'V164',  # V features \n",
    "    'V166', 'V172', 'V173', 'V174', 'V175', 'V176',  # V features \n",
    "    'V177', 'V178', 'V179', 'V180', 'V181', 'V182',  # V features  \n",
    "    'V183', 'V184', 'V185', 'V186', 'V190', 'V191',  # V features  \n",
    "    'V192', 'V193', 'V194', 'V195', 'V196', 'V197',  # V features  \n",
    "    'V198', 'V199', 'V214', 'V216', 'V220', 'V225',  # V features \n",
    "    'V226', 'V227', 'V230', 'V233', 'V235', 'V236',  # V features  \n",
    "    'V237', 'V238', 'V239', 'V240', 'V241', 'V242',  # V features \n",
    "    'V244', 'V246', 'V247', 'V248', 'V249', 'V250',  # V features \n",
    "    'V252', 'V254', 'V255', 'V269', 'V276', 'V297',  # V features \n",
    "    'V300', 'V302', 'V304', 'V305', 'V325', 'V327',  # V features  \n",
    "    'V328', 'V329', 'V330', 'V334', 'V335', 'V336',  # V features \n",
    "    'V337', 'V338', 'V339',  # V features \n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard OS versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_os_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_30 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after os versions have been ignored\n",
    "    \"\"\"\n",
    "    os_list = [\n",
    "        'Android',\n",
    "        'iOS',\n",
    "        'Mac OS X',\n",
    "        'Windows',\n",
    "    ]\n",
    "\n",
    "    for index, operating_system in df.id_30.iteritems():\n",
    "        new_os = 'other'\n",
    "\n",
    "        if isinstance(operating_system, str):\n",
    "            for known_os in os_list:\n",
    "                if known_os in operating_system:\n",
    "                    new_os = known_os\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_30'] = new_os\n",
    "\n",
    "    if verbose:\n",
    "        print('operating systems:', df.id_30.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to disregard browser versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_browser_version(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - df (DataFrame): has id_31 as one of its columns\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, after browser versions have been ignored\n",
    "    \"\"\"\n",
    "    browser_list = [\n",
    "        'aol',\n",
    "        'chrome',\n",
    "        'chromium',\n",
    "        'comodo',\n",
    "        'cyberfox',\n",
    "        'edge',\n",
    "        'firefox',\n",
    "        'icedragon',\n",
    "        'ie',\n",
    "        'iron',\n",
    "        'maxthon',\n",
    "        'opera',\n",
    "        'palemoon',\n",
    "        'puffin',\n",
    "        'safari',\n",
    "        'samsung',\n",
    "        'seamonkey',\n",
    "        'silk',\n",
    "        'waterfox',\n",
    "    ]\n",
    "\n",
    "    for index, browser in df.id_31.iteritems():\n",
    "        new_browser = 'other'\n",
    "\n",
    "        if isinstance(browser, str):\n",
    "            for known_browser in browser_list:\n",
    "                if known_browser in browser:\n",
    "                    new_browser = known_browser\n",
    "                    break\n",
    "\n",
    "        df.at[index, 'id_31'] = new_browser\n",
    "\n",
    "    if verbose:\n",
    "        print('browsers:', df.id_31.unique())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, verbose: bool=True):\n",
    "    \"\"\"\n",
    "    Does the following preprocessing steps:\n",
    "    - disregard os versions\n",
    "    - disregard browser versions\n",
    "    - drop useless features\n",
    "    - convert object columns to string columns\n",
    "    - imputation (for numbers, fill with interquartile mean)\n",
    "    - do label encoding for non-numeric values\n",
    "    - reduce memory usage again\n",
    "\n",
    "    params:   \n",
    "    - df (DataFrame): dataframe to preprocess (has columns id_30 and id_31)\n",
    "    - verbose (bool): prints information if True\n",
    "\n",
    "    return: dataframe, preprocessing is complete\n",
    "    \"\"\"\n",
    "    df = df.drop(useless_features, axis=1)\n",
    "    df = ignore_os_version(df, verbose)\n",
    "    df = ignore_browser_version(df, verbose)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column]= df[column].astype(str)\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].quantile().mean())\n",
    "\n",
    "    df = reduce_mem_usage(df, verbose)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 542.35 Mb (69.4% reduction)\nMem. usage decreased to 25.86 Mb (42.7% reduction)\nnumber of rows in training data: 590540\noperating systems: ['other' 'Android' 'iOS' 'Mac OS X' 'Windows']\nbrowsers: ['other' 'samsung' 'safari' 'chrome' 'edge' 'firefox' 'ie' 'opera' 'aol'\n 'silk' 'waterfox' 'puffin' 'cyberfox' 'palemoon' 'maxthon' 'iron'\n 'seamonkey' 'comodo' 'chromium' 'icedragon']\nMem. usage decreased to 357.35 Mb (22.1% reduction)\nCPU times: user 1min 15s, sys: 36.1 s, total: 1min 51s\nWall time: 1min 51s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   isFraud  TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  \\\n0        0          86400            68.5          4  13926  361.0  150.0   \n1        0          86401            29.0          4   2755  404.0  150.0   \n2        0          86469            59.0          4   4663  490.0  150.0   \n3        0          86499            50.0          4  18132  567.0  150.0   \n4        0          86506            50.0          1   4497  514.0  150.0   \n\n   card4  card5  card6  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0      1  142.0      1  ...      4     12   24.0    260      4      2      2   \n1      2  102.0      1  ...      4     12   24.0    260      4      2      2   \n2      4  166.0      2  ...      4     12   24.0    260      4      2      2   \n3      2  117.0      2  ...      4     12   24.0    260      4      2      2   \n4      2  102.0      1  ...      0     16   32.0    164      3      0      1   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        1742  \n1      2           2        1742  \n2      2           2        1742  \n3      2           2        1742  \n4      1           1         954  \n\n[5 rows x 270 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>86400</td>\n      <td>68.5</td>\n      <td>4</td>\n      <td>13926</td>\n      <td>361.0</td>\n      <td>150.0</td>\n      <td>1</td>\n      <td>142.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>86401</td>\n      <td>29.0</td>\n      <td>4</td>\n      <td>2755</td>\n      <td>404.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>86469</td>\n      <td>59.0</td>\n      <td>4</td>\n      <td>4663</td>\n      <td>490.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>86499</td>\n      <td>50.0</td>\n      <td>4</td>\n      <td>18132</td>\n      <td>567.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>24.0</td>\n      <td>260</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>86506</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>4497</td>\n      <td>514.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>102.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16</td>\n      <td>32.0</td>\n      <td>164</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>954</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 270 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(train_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(train_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in training data: {len(dataframe)}')\n",
    "dataframe = preprocess(dataframe)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate data into features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataframe = dataframe.drop('isFraud', axis=1)\n",
    "is_fraud_data = dataframe['isFraud']\n",
    "\n",
    "del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define number of base classifiers and splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'features_dataframe' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6a6514aa7fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_base_classifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_fraud_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "num_base_classifiers = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_base_classifiers)\n",
    "splits = skf.split(features_dataframe, is_fraud_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train LightGBM\n",
    "\n",
    "- using [reference notebook parameters](https://www.kaggle.com/nroman/lgb-single-model-lb-0-9419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 491,\n",
    "    'min_child_weight': 0.03454472573214212,\n",
    "    'feature_fraction': 0.3797454081646243,\n",
    "    'bagging_fraction': 0.4181193142567742,\n",
    "    'min_data_in_leaf': 106,\n",
    "    'objective': 'binary',\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.006883242363721497,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'bagging_seed': 11,\n",
    "    'metric': 'auc',\n",
    "    'verbosity': -1,\n",
    "    'reg_alpha': 0.3899927210061127,\n",
    "    'reg_lambda': 0.6485237330340494,\n",
    "    'random_state': 47,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "working on base classifier 0\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993331\tvalid_1's auc: 0.922561\n[2000]\ttraining's auc: 0.999021\tvalid_1's auc: 0.92448\n[3000]\ttraining's auc: 0.99983\tvalid_1's auc: 0.924896\nEarly stopping, best iteration is:\n[3067]\ttraining's auc: 0.999852\tvalid_1's auc: 0.925013\nbase classifier 0 AUC: 0.9250127368401669\nworking on base classifier 1\nTraining until validation scores don't improve for 500 rounds\nEarly stopping, best iteration is:\n[5]\ttraining's auc: 0.913302\tvalid_1's auc: 0.869541\nbase classifier 1 AUC: 0.8695406977885869\nworking on base classifier 2\nTraining until validation scores don't improve for 500 rounds\nEarly stopping, best iteration is:\n[5]\ttraining's auc: 0.915128\tvalid_1's auc: 0.867287\nbase classifier 2 AUC: 0.867287285256501\nworking on base classifier 3\nTraining until validation scores don't improve for 500 rounds\nEarly stopping, best iteration is:\n[7]\ttraining's auc: 0.913543\tvalid_1's auc: 0.90259\nbase classifier 3 AUC: 0.9025903179222663\nworking on base classifier 4\nTraining until validation scores don't improve for 500 rounds\nEarly stopping, best iteration is:\n[456]\ttraining's auc: 0.971779\tvalid_1's auc: 0.912402\nbase classifier 4 AUC: 0.9124024624399112\nworking on base classifier 5\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993494\tvalid_1's auc: 0.907932\nEarly stopping, best iteration is:\n[726]\ttraining's auc: 0.98725\tvalid_1's auc: 0.913042\nbase classifier 5 AUC: 0.9130419756514014\nworking on base classifier 6\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.993009\tvalid_1's auc: 0.947661\nEarly stopping, best iteration is:\n[1147]\ttraining's auc: 0.994974\tvalid_1's auc: 0.948094\nbase classifier 6 AUC: 0.9480944035975442\nworking on base classifier 7\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.992539\tvalid_1's auc: 0.958538\n[2000]\ttraining's auc: 0.998974\tvalid_1's auc: 0.961779\nEarly stopping, best iteration is:\n[2139]\ttraining's auc: 0.999181\tvalid_1's auc: 0.961958\nbase classifier 7 AUC: 0.9619583834841801\nworking on base classifier 8\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.992959\tvalid_1's auc: 0.947042\n[2000]\ttraining's auc: 0.999014\tvalid_1's auc: 0.952162\n[3000]\ttraining's auc: 0.999816\tvalid_1's auc: 0.952852\nEarly stopping, best iteration is:\n[2982]\ttraining's auc: 0.99981\tvalid_1's auc: 0.952892\nbase classifier 8 AUC: 0.9528922768685164\nworking on base classifier 9\nTraining until validation scores don't improve for 500 rounds\n[1000]\ttraining's auc: 0.992912\tvalid_1's auc: 0.934762\nEarly stopping, best iteration is:\n[988]\ttraining's auc: 0.992737\tvalid_1's auc: 0.934846\nbase classifier 9 AUC: 0.9348455701993468\nCPU times: user 12h 6min 57s, sys: 9min 33s, total: 12h 16min 30s\nWall time: 1h 5min 9s\n"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, (train_index, val_index) in enumerate(splits):\n",
    "    print(f'working on base classifier {index}')\n",
    "\n",
    "    train_data = lgb.Dataset(\n",
    "        features_dataframe.iloc[train_index],\n",
    "        is_fraud_data.iloc[train_index],\n",
    "    )\n",
    "\n",
    "    val_features = features_dataframe.iloc[val_index]\n",
    "    val_target = is_fraud_data.iloc[val_index]\n",
    "    val_data = lgb.Dataset(val_features, val_target)\n",
    "\n",
    "    params['random_state'] = index\n",
    "\n",
    "    classifier = lgb.train(\n",
    "        params, \n",
    "        train_set=train_data, \n",
    "        num_boost_round=10000, \n",
    "        valid_sets=[train_data, val_data],\n",
    "        verbose_eval=1000,\n",
    "        early_stopping_rounds=500,\n",
    "    )\n",
    "\n",
    "    joblib.dump(classifier, model_dir_path + 'lgbm_' + str(index) + '.joblib')\n",
    "\n",
    "    prediction = classifier.predict(val_features)\n",
    "    auc = roc_auc_score(val_target, prediction)\n",
    "    print(f'base classifier {index} AUC: {auc}')\n",
    "\n",
    "del features_dataframe\n",
    "del is_fraud_data\n",
    "\n",
    "del skf\n",
    "del splits\n",
    "\n",
    "del params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 472.59 Mb (68.9% reduction)\nMem. usage decreased to 25.44 Mb (42.7% reduction)\nnumber of rows in test data: 506691\noperating systems: ['other' 'Android' 'iOS' 'Windows' 'Mac OS X']\nbrowsers: ['other' 'chrome' 'ie' 'safari' 'edge' 'firefox' 'samsung' 'opera'\n 'palemoon']\nMem. usage decreased to 315.73 Mb (21.6% reduction)\nCPU times: user 1min 7s, sys: 32.3 s, total: 1min 39s\nWall time: 1min 40s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionDT  TransactionAmt  ProductCD  card1  card2  card3  card4  \\\n0       18403224       31.953125          4  10409  111.0  150.0      4   \n1       18403263       49.000000          4   4272  111.0  150.0      4   \n2       18403310      171.000000          4   4476  574.0  150.0      4   \n3       18403310      285.000000          4  10989  360.0  150.0      4   \n4       18403317       67.937500          4  18018  452.0  150.0      2   \n\n   card5  card6  addr1  ...  id_30  id_31  id_32  id_33  id_34  id_36  id_37  \\\n0  226.0      2  170.0  ...      4      5   24.0    390      2      2      2   \n1  226.0      2  299.0  ...      4      5   24.0    390      2      2      2   \n2  226.0      2  472.0  ...      4      5   24.0    390      2      2      2   \n3  166.0      2  205.0  ...      4      5   24.0    390      2      2      2   \n4  117.0      2  264.0  ...      4      5   24.0    390      2      2      2   \n\n   id_38  DeviceType  DeviceInfo  \n0      2           2        2184  \n1      2           2        2184  \n2      2           2        2184  \n3      2           2        2184  \n4      2           2        2184  \n\n[5 rows x 269 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>card6</th>\n      <th>addr1</th>\n      <th>...</th>\n      <th>id_30</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18403224</td>\n      <td>31.953125</td>\n      <td>4</td>\n      <td>10409</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>170.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18403263</td>\n      <td>49.000000</td>\n      <td>4</td>\n      <td>4272</td>\n      <td>111.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>299.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18403310</td>\n      <td>171.000000</td>\n      <td>4</td>\n      <td>4476</td>\n      <td>574.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>226.0</td>\n      <td>2</td>\n      <td>472.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18403310</td>\n      <td>285.000000</td>\n      <td>4</td>\n      <td>10989</td>\n      <td>360.0</td>\n      <td>150.0</td>\n      <td>4</td>\n      <td>166.0</td>\n      <td>2</td>\n      <td>205.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18403317</td>\n      <td>67.937500</td>\n      <td>4</td>\n      <td>18018</td>\n      <td>452.0</td>\n      <td>150.0</td>\n      <td>2</td>\n      <td>117.0</td>\n      <td>2</td>\n      <td>264.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>24.0</td>\n      <td>390</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2184</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 269 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transaction_dataframe = pd.read_csv(test_transaction_data_path)\n",
    "transaction_dataframe = reduce_mem_usage(transaction_dataframe)\n",
    "\n",
    "identity_dataframe = pd.read_csv(test_identity_data_path)\n",
    "identity_dataframe = reduce_mem_usage(identity_dataframe)\n",
    "identity_dataframe = identity_dataframe.rename(\n",
    "    columns={\n",
    "        column: column.replace('-', '_')\n",
    "        for column in identity_dataframe.columns\n",
    "    }\n",
    ")\n",
    "\n",
    "dataframe = transaction_dataframe.merge(identity_dataframe, how='outer')\n",
    "transaction_id_data = dataframe['TransactionID']  # need it for output\n",
    "\n",
    "del transaction_dataframe\n",
    "del identity_dataframe\n",
    "\n",
    "print(f'number of rows in test data: {len(dataframe)}')\n",
    "dataframe = preprocess(dataframe)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model\n",
    "\n",
    "- if model is no longer in memory (e.g. due to restarting of notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    joblib.load(model_dir_path + 'lgbm_' + str(index) + '.joblib')\n",
    "    for index in range(num_base_classifiers)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do inference and get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 57min 54s, sys: 9.76 s, total: 58min 4s\nWall time: 5min 31s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   TransactionID   isFraud\n0        3663549  0.012192\n1        3663550  0.011900\n2        3663551  0.015791\n3        3663552  0.012669\n4        3663553  0.011967",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3663549</td>\n      <td>0.012192</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3663550</td>\n      <td>0.011900</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3663551</td>\n      <td>0.015791</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3663552</td>\n      <td>0.012669</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3663553</td>\n      <td>0.011967</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = [\n",
    "    classifier.predict(dataframe)\n",
    "    for classifier in classifiers\n",
    "]\n",
    "\n",
    "prediction = predictions.pop()\n",
    "for pred in predictions:\n",
    "    prediction += pred\n",
    "\n",
    "prediction /= 10  # equal weightage given to each base classifier - 0.1\n",
    "del predictions\n",
    "\n",
    "del classifiers\n",
    "del dataframe\n",
    "\n",
    "output_dataframe = pd.DataFrame({\n",
    "    'TransactionID': transaction_id_data,\n",
    "    'isFraud': pd.Series(prediction),\n",
    "})\n",
    "\n",
    "output_dataframe.to_csv(output_dir_path + 'ensemble_lgbm.csv', index=False)\n",
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle result\n",
    "\n",
    "- public score: 0.939414\n",
    "- public ranking: 3513 out of 6381 (~55.05%)\n",
    "- private score: 0.915039\n",
    "- private ranking: 2659 out of 6381 (~41.67%)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0656ffb61a14454b8758eedef206058e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}